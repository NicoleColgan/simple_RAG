"""Pinecone db to store embeddings generated by Vertex ai"""
from pinecone import Pinecone, ServerlessSpec
from config import PINECONE_API_KEY, PINECONE_INDEX_NAME, PINECONE_DIMENSION, PINECONE_METRIC, PINECONE_CLOUD, PINECONE_REGION
import logging

logger = logging.getLogger(__name__)

class VectorStore:
    def __init__(self):
        self.pinecone_client = Pinecone(PINECONE_API_KEY)
        self.ensure_index_exists()
        self.index = self.pinecone_client.Index(PINECONE_INDEX_NAME)
        logger.info(f"Connected to pinecone index: {PINECONE_INDEX_NAME}")
    
    def ensure_index_exists(self):
        if not self.pinecone_client.has_index(PINECONE_INDEX_NAME):
            self.pinecone_client.create_index(
                name=PINECONE_INDEX_NAME,
                dimension=PINECONE_DIMENSION,
                metric="cosine",
                spec=ServerlessSpec(cloud=PINECONE_CLOUD, region=PINECONE_REGION)
            )

    def upload_to_pinecone(self, vectors):
        self.index.upsert(vectors=vectors)
        logger.info("vectors uploaded to Pinecone db")

    def filter_existing_vectors(self, chunks):
        ids = [chunk["id"] for chunk in chunks]
        existing_chunks = self.index.fetch(ids=ids)
        logger.info(f"chunks already in pincone: {existing_chunks.get("vectors", {})}")
        return [chunk for chunk in chunks if chunk["id"] not in existing_chunks.get("vectors", {})] # will this return [] and be fine if filter all out?

    #  def query(self, query_vector: list[float], top_k: int = 5) -> list[dict]:
    #     """Query Pinecone for similar vectors"""
    #     results = self.index.query(
    #         vector=query_vector,
    #         top_k=top_k,
    #         include_metadata=True
    #     )
    #     return results.get("matches", [])